{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "from pyflink.table import EnvironmentSettings, TableEnvironment\n",
    "\n",
    "import ibis\n",
    "import ibis.expr.datatypes as dt\n",
    "import ibis.expr.schema as sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file object: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m consumer \u001b[39m=\u001b[39m KafkaConsumer(\u001b[39m\"\u001b[39;49m\u001b[39mtransaction\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m msg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m), consumer):\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(msg)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/consumer/group.py:356\u001b[0m, in \u001b[0;36mKafkaConsumer.__init__\u001b[0;34m(self, *topics, **configs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mapi_version\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mint\u001b[39m, str_version\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m    353\u001b[0m     log\u001b[39m.\u001b[39mwarning(\u001b[39m'\u001b[39m\u001b[39muse api_version=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m [tuple] -- \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m as str is deprecated\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    354\u001b[0m                 \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mapi_version\u001b[39m\u001b[39m'\u001b[39m]), str_version)\n\u001b[0;32m--> 356\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client \u001b[39m=\u001b[39m KafkaClient(metrics\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_metrics, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig)\n\u001b[1;32m    358\u001b[0m \u001b[39m# Get auto-discovered version from client if necessary\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mapi_version\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/client_async.py:244\u001b[0m, in \u001b[0;36mKafkaClient.__init__\u001b[0;34m(self, **configs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mapi_version\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     check_timeout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mapi_version_auto_timeout_ms\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m--> 244\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mapi_version\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_version(timeout\u001b[39m=\u001b[39;49mcheck_timeout)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/client_async.py:909\u001b[0m, in \u001b[0;36mKafkaClient.check_version\u001b[0;34m(self, node_id, timeout, strict)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m     remaining \u001b[39m=\u001b[39m end \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 909\u001b[0m     version \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mcheck_version(timeout\u001b[39m=\u001b[39;49mremaining, strict\u001b[39m=\u001b[39;49mstrict, topics\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mbootstrap_topics_filter\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n\u001b[1;32m    910\u001b[0m     \u001b[39mif\u001b[39;00m version \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m0\u001b[39m):\n\u001b[1;32m    911\u001b[0m         \u001b[39m# cache the api versions map if it's available (starting\u001b[39;00m\n\u001b[1;32m    912\u001b[0m         \u001b[39m# in 0.10 cluster version)\u001b[39;00m\n\u001b[1;32m    913\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_api_versions \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mget_api_versions()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/conn.py:1254\u001b[0m, in \u001b[0;36mBrokerConnection.check_version\u001b[0;34m(self, timeout, strict, topics)\u001b[0m\n\u001b[1;32m   1251\u001b[0m mr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(MetadataRequest[\u001b[39m0\u001b[39m](topics))\n\u001b[1;32m   1253\u001b[0m selector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mselector\u001b[39m\u001b[39m'\u001b[39m]()\n\u001b[0;32m-> 1254\u001b[0m selector\u001b[39m.\u001b[39;49mregister(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock, selectors\u001b[39m.\u001b[39;49mEVENT_READ)\n\u001b[1;32m   1255\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m (f\u001b[39m.\u001b[39mis_done \u001b[39mand\u001b[39;00m mr\u001b[39m.\u001b[39mis_done):\n\u001b[1;32m   1256\u001b[0m     selector\u001b[39m.\u001b[39mselect(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/selectors.py:353\u001b[0m, in \u001b[0;36m_PollLikeSelector.register\u001b[0;34m(self, fileobj, events, data)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregister\u001b[39m(\u001b[39mself\u001b[39m, fileobj, events, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 353\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mregister(fileobj, events, data)\n\u001b[1;32m    354\u001b[0m     poller_events \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    355\u001b[0m     \u001b[39mif\u001b[39;00m events \u001b[39m&\u001b[39m EVENT_READ:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/selectors.py:239\u001b[0m, in \u001b[0;36m_BaseSelectorImpl.register\u001b[0;34m(self, fileobj, events, data)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m events) \u001b[39mor\u001b[39;00m (events \u001b[39m&\u001b[39m \u001b[39m~\u001b[39m(EVENT_READ \u001b[39m|\u001b[39m EVENT_WRITE)):\n\u001b[1;32m    237\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid events: \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(events))\n\u001b[0;32m--> 239\u001b[0m key \u001b[39m=\u001b[39m SelectorKey(fileobj, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fileobj_lookup(fileobj), events, data)\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mfd \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fd_to_key:\n\u001b[1;32m    242\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m (FD \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is already registered\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m                    \u001b[39m.\u001b[39mformat(fileobj, key\u001b[39m.\u001b[39mfd))\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/selectors.py:226\u001b[0m, in \u001b[0;36m_BaseSelectorImpl._fileobj_lookup\u001b[0;34m(self, fileobj)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return a file descriptor from a file object.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \n\u001b[1;32m    219\u001b[0m \u001b[39mThis wraps _fileobj_to_fd() to do an exhaustive search in case\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mused by _SelectorMapping.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m _fileobj_to_fd(fileobj)\n\u001b[1;32m    227\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     \u001b[39m# Do an exhaustive search.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fd_to_key\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/selectors.py:39\u001b[0m, in \u001b[0;36m_fileobj_to_fd\u001b[0;34m(fileobj)\u001b[0m\n\u001b[1;32m     37\u001b[0m         fd \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(fileobj\u001b[39m.\u001b[39mfileno())\n\u001b[1;32m     38\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m---> 39\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid file object: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(fileobj)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m fd \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid file descriptor: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(fd))\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file object: None"
     ]
    }
   ],
   "source": [
    "consumer = KafkaConsumer(\"transaction\")\n",
    "for msg in zip(range(10), consumer):\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x7f2465798c10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local = True\n",
    "\n",
    "# 1. create a TableEnvironment\n",
    "env_settings = EnvironmentSettings.in_streaming_mode()\n",
    "table_env = TableEnvironment.create(env_settings)\n",
    "# write all the data to one file\n",
    "table_env.get_config().set(\"parallelism.default\", \"1\")\n",
    "\n",
    "# The `flink` backend does not create `TableEnvironment` objects; pass\n",
    "# the `TableEnvironment` object created above to `ibis.flink.connect`.\n",
    "connection = ibis.flink.connect(table_env)\n",
    "\n",
    "# Flinkâ€™s streaming connectors aren't part of the binary distribution.\n",
    "# Link the Kafka connector for cluster execution by adding a JAR file.\n",
    "connection._exec_sql(\"ADD JAR '../../flink-sql-connector-kafka-3.0.2-1.18.jar'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create source table\n",
    "source_topic_name = \"transaction\"\n",
    "kafka_offset = \"earliest-offset\"\n",
    "source_schema = sch.Schema(\n",
    "    {\n",
    "        \"user_id\": dt.int64,\n",
    "        \"trans_date_trans_time\": dt.timestamp(scale=3),\n",
    "        \"cc_num\": dt.int64,\n",
    "        \"amt\": dt.float64,\n",
    "        \"trans_num\": dt.str,\n",
    "        \"merchant\": dt.str,\n",
    "        \"category\": dt.str ,      \n",
    "        \"is_fraud\": dt.int32,\n",
    "        \"first\": dt.str,\n",
    "        \"last\": dt.str,\n",
    "        \"dob\": dt.str,\n",
    "        \"zipcode\": dt.str,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Configure the source table with Kafka connector properties.\n",
    "source_configs = {\n",
    "    \"connector\": \"kafka\",\n",
    "    \"topic\": source_topic_name,\n",
    "    \"properties.bootstrap.servers\": \"localhost:9092\" if local else \"kafka:29092\",\n",
    "    \"properties.group.id\": \"test\",\n",
    "    \"scan.startup.mode\": kafka_offset,\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "\n",
    "# Create the source table using the defined schema, Kafka connector properties,\n",
    "# and set watermarking for real-time processing with a 15-second delay.\n",
    "source_table = connection.create_table(\n",
    "    source_topic_name,\n",
    "    schema=source_schema,\n",
    "    tbl_properties=source_configs,\n",
    "    watermark=ibis.watermark(\n",
    "        time_col=\"trans_date_trans_time\", allowed_delay=ibis.interval(seconds=15)\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">DatabaseTable: transaction\n",
       "  user_id               int64\n",
       "  trans_date_trans_time timestamp(3)\n",
       "  cc_num                int64\n",
       "  amt                   float64\n",
       "  trans_num             string\n",
       "  merchant              string\n",
       "  category              string\n",
       "  is_fraud              int32\n",
       "  first                 string\n",
       "  last                  string\n",
       "  dob                   string\n",
       "  zipcode               string\n",
       "</pre>\n"
      ],
      "text/plain": [
       "DatabaseTable: transaction\n",
       "  user_id               int64\n",
       "  trans_date_trans_time timestamp(3)\n",
       "  cc_num                int64\n",
       "  amt                   float64\n",
       "  trans_num             string\n",
       "  merchant              string\n",
       "  category              string\n",
       "  is_fraud              int32\n",
       "  first                 string\n",
       "  last                  string\n",
       "  dob                   string\n",
       "  zipcode               string"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">r0 := DatabaseTable: transaction\n",
       "  user_id               int64\n",
       "  trans_date_trans_time timestamp(3)\n",
       "  cc_num                int64\n",
       "  amt                   float64\n",
       "  trans_num             string\n",
       "  merchant              string\n",
       "  category              string\n",
       "  is_fraud              int32\n",
       "  first                 string\n",
       "  last                  string\n",
       "  dob                   string\n",
       "  zipcode               string\n",
       "\n",
       "Selection[r0]\n",
       "  selections:\n",
       "    user_id:                      r0.user_id\n",
       "    user_max_trans_amt_last_5min: WindowFunction(func=Max(r0.amt), frame=RangeWindowFrame(table=r0, \n",
       "start=WindowBoundary(value=5 m, preceding=True), end=WindowBoundary(Cast(0, to=interval('m'))), \n",
       "group_by=[r0.user_id], order_by=[asc r0.trans_date_trans_time]))\n",
       "    user_min_trans_amt_last_5min: WindowFunction(func=Min(r0.amt), frame=RangeWindowFrame(table=r0, \n",
       "start=WindowBoundary(value=5 m, preceding=True), end=WindowBoundary(Cast(0, to=interval('m'))), \n",
       "group_by=[r0.user_id], order_by=[asc r0.trans_date_trans_time]))\n",
       "    trans_date_trans_time:        r0.trans_date_trans_time\n",
       "</pre>\n"
      ],
      "text/plain": [
       "r0 := DatabaseTable: transaction\n",
       "  user_id               int64\n",
       "  trans_date_trans_time timestamp(3)\n",
       "  cc_num                int64\n",
       "  amt                   float64\n",
       "  trans_num             string\n",
       "  merchant              string\n",
       "  category              string\n",
       "  is_fraud              int32\n",
       "  first                 string\n",
       "  last                  string\n",
       "  dob                   string\n",
       "  zipcode               string\n",
       "\n",
       "Selection[r0]\n",
       "  selections:\n",
       "    user_id:                      r0.user_id\n",
       "    user_max_trans_amt_last_5min: WindowFunction(func=Max(r0.amt), frame=RangeWindowFrame(table=r0, \n",
       "start=WindowBoundary(value=5 m, preceding=True), end=WindowBoundary(Cast(0, to=interval('m'))), \n",
       "group_by=[r0.user_id], order_by=[asc r0.trans_date_trans_time]))\n",
       "    user_min_trans_amt_last_5min: WindowFunction(func=Min(r0.amt), frame=RangeWindowFrame(table=r0, \n",
       "start=WindowBoundary(value=5 m, preceding=True), end=WindowBoundary(Cast(0, to=interval('m'))), \n",
       "group_by=[r0.user_id], order_by=[asc r0.trans_date_trans_time]))\n",
       "    trans_date_trans_time:        r0.trans_date_trans_time"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Feature Generation using Flink backend\n",
    "# Define a window specification for aggregating maximum transaction amount over the last 5 minutes.\n",
    "# The aggregation is partitioned by user_id and ordered by trans_date_trans_time.\n",
    "# The window range is set to the interval from 5 minutes ago to the current time.\n",
    "user_trans_amt_agg = source_table[\n",
    "    source_table.user_id,\n",
    "    # Calculate the maximum transaction amount over the specified window.\n",
    "    source_table.amt.max().over(\n",
    "        ibis.window(\n",
    "            group_by=source_table.user_id,\n",
    "            order_by=source_table.trans_date_trans_time,\n",
    "            range=(-ibis.interval(minutes=360), 0),\n",
    "        )\n",
    "    ).name(\"user_max_trans_amt_last_60min\"),\n",
    "    # Calculate the min transaction amount over the specified window.\n",
    "    source_table.amt.min().over(\n",
    "        ibis.window(\n",
    "            group_by=source_table.user_id,\n",
    "            order_by=source_table.trans_date_trans_time,\n",
    "            range=(-ibis.interval(minutes=360), 0),\n",
    "        )\n",
    "    ).name(\"user_min_trans_amt_last_60min\"),\n",
    "    # Calculate the average transaction amount over the specified window.\n",
    "    source_table.amt.mean().over(\n",
    "        ibis.window(\n",
    "            group_by=source_table.user_id,\n",
    "            order_by=source_table.trans_date_trans_time,\n",
    "            range=(-ibis.interval(minutes=360), 0),\n",
    "        )\n",
    "    ).name(\"user_mean_trans_amt_last_60min\"),\n",
    "    source_table.trans_date_trans_time\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">DatabaseTable: user_max_trans_amt_last_5min\n",
       "  user_id                      int64\n",
       "  user_max_trans_amt_last_5min float64\n",
       "  user_min_trans_amt_last_5min float64\n",
       "  trans_date_trans_time        timestamp(3)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "DatabaseTable: user_max_trans_amt_last_5min\n",
       "  user_id                      int64\n",
       "  user_max_trans_amt_last_5min float64\n",
       "  user_min_trans_amt_last_5min float64\n",
       "  trans_date_trans_time        timestamp(3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Creat Sink\n",
    "sink_topic_name = \"user_trans_amt_last_360min\"\n",
    "sink_schema = sch.Schema(\n",
    "    {\n",
    "        \"user_id\": dt.int64,\n",
    "        \"user_max_trans_amt_last_5min\": dt.float64,\n",
    "        \"user_min_trans_amt_last_5min\": dt.float64,\n",
    "        \"trans_date_trans_time\": dt.timestamp(scale=3), # used for future temporal join\n",
    "    }\n",
    ")\n",
    "\n",
    "# Configure the sink table with Kafka connector properties for writing results.\n",
    "sink_configs = {\n",
    "    \"connector\": \"kafka\",\n",
    "    \"topic\": sink_topic_name,\n",
    "    \"properties.bootstrap.servers\": \"localhost:9092\" if local else \"kafka:29092\",\n",
    "    \"format\": \"debezium-json\", # \"debezium-json\" is needed for future temporal join.\n",
    "}\n",
    "\n",
    "sink_table = connection.create_table(\n",
    "    sink_topic_name, schema=sink_schema, tbl_properties=sink_configs, overwrite=True\n",
    ")\n",
    "sink_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x7f24b0b52fe0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Emit query result to sink table\n",
    "connection.insert(sink_topic_name, user_max_trans_amt_last_5min)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConsumerRecord(topic='user_max_trans_amt_last_5min', partition=0, offset=1444, timestamp=1705533214152, timestamp_type=0, key=None, value=b'{\"before\":null,\"after\":{\"user_id\":-5404855628358389721,\"user_max_trans_amt_last_5min\":96.29,\"user_min_trans_amt_last_5min\":96.29,\"trans_date_trans_time\":\"2024-01-17 23:13:18.824\"},\"op\":\"c\"}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=189, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='user_max_trans_amt_last_5min', partition=0, offset=1445, timestamp=1705533216354, timestamp_type=0, key=None, value=b'{\"before\":null,\"after\":{\"user_id\":-4479665259876654427,\"user_max_trans_amt_last_5min\":7.77,\"user_min_trans_amt_last_5min\":7.77,\"trans_date_trans_time\":\"2024-01-17 23:13:19.525\"},\"op\":\"c\"}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=187, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='user_max_trans_amt_last_5min', partition=0, offset=1446, timestamp=1705533216354, timestamp_type=0, key=None, value=b'{\"before\":null,\"after\":{\"user_id\":8007529102478895860,\"user_max_trans_amt_last_5min\":3.26,\"user_min_trans_amt_last_5min\":3.26,\"trans_date_trans_time\":\"2024-01-17 23:13:19.84\"},\"op\":\"c\"}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=185, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='user_max_trans_amt_last_5min', partition=0, offset=1447, timestamp=1705533220959, timestamp_type=0, key=None, value=b'{\"before\":null,\"after\":{\"user_id\":-2697926096031198188,\"user_max_trans_amt_last_5min\":327.0,\"user_min_trans_amt_last_5min\":327.0,\"trans_date_trans_time\":\"2024-01-17 23:13:22.766\"},\"op\":\"c\"}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=189, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='user_max_trans_amt_last_5min', partition=0, offset=1448, timestamp=1705533224563, timestamp_type=0, key=None, value=b'{\"before\":null,\"after\":{\"user_id\":-1533385361042585948,\"user_max_trans_amt_last_5min\":341.67,\"user_min_trans_amt_last_5min\":341.67,\"trans_date_trans_time\":\"2024-01-17 23:13:26.197\"},\"op\":\"c\"}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=191, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='user_max_trans_amt_last_5min', partition=0, offset=1449, timestamp=1705533225764, timestamp_type=0, key=None, value=b'{\"before\":null,\"after\":{\"user_id\":-2865594945187072540,\"user_max_trans_amt_last_5min\":63.07,\"user_min_trans_amt_last_5min\":63.07,\"trans_date_trans_time\":\"2024-01-17 23:13:29.928\"},\"op\":\"c\"}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=189, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='user_max_trans_amt_last_5min', partition=0, offset=1450, timestamp=1705533229568, timestamp_type=0, key=None, value=b'{\"before\":null,\"after\":{\"user_id\":-2150257071961866142,\"user_max_trans_amt_last_5min\":44.71,\"user_min_trans_amt_last_5min\":44.71,\"trans_date_trans_time\":\"2024-01-17 23:13:32.579\"},\"op\":\"c\"}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=189, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='user_max_trans_amt_last_5min', partition=0, offset=1451, timestamp=1705533229568, timestamp_type=0, key=None, value=b'{\"before\":null,\"after\":{\"user_id\":-7687982869728990324,\"user_max_trans_amt_last_5min\":57.34,\"user_min_trans_amt_last_5min\":57.34,\"trans_date_trans_time\":\"2024-01-17 23:13:33.366\"},\"op\":\"c\"}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=189, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='user_max_trans_amt_last_5min', partition=0, offset=1452, timestamp=1705533229568, timestamp_type=0, key=None, value=b'{\"before\":null,\"after\":{\"user_id\":3455235306140184938,\"user_max_trans_amt_last_5min\":50.79,\"user_min_trans_amt_last_5min\":50.79,\"trans_date_trans_time\":\"2024-01-17 23:13:33.947\"},\"op\":\"c\"}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=188, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='user_max_trans_amt_last_5min', partition=0, offset=1453, timestamp=1705533234973, timestamp_type=0, key=None, value=b'{\"before\":null,\"after\":{\"user_id\":4983856883276548737,\"user_max_trans_amt_last_5min\":46.28,\"user_min_trans_amt_last_5min\":46.28,\"trans_date_trans_time\":\"2024-01-17 23:13:36.19\"},\"op\":\"c\"}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=187, serialized_header_size=-1)\n"
     ]
    }
   ],
   "source": [
    "if local:\n",
    "    # Use the Kafka Python client to stream records from the sink topic.\n",
    "    # Otherwise, the mini cluster will shut down upon script completion.\n",
    "    consumer = KafkaConsumer(sink_topic_name)\n",
    "    for _, msg in zip(range(10), consumer):\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
